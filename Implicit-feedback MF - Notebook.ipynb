{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aalto Matrix Compeltion  \n",
    "## recommendation problem for Music (an in class Kaggle challenge)\n",
    "#### https://inclass.kaggle.com/c/aalto-music-listening-prediction\n",
    "### Realised by :  Sakly Sami ,Roodnejad Maxime  \n",
    "### Master Class AIC - UPSay                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data were in the form of matlab (.mat) files. So we had convert them to csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_number = np.shape(raw_data_transformed)[0]\n",
    "item_number = np.shape(raw_data_transformed)[1]\n",
    "print \"number of user X number of artists : \", np.shape(raw_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the first issue after converting the data to csv is that the value we are going to predict \n",
    "# are left empty (not a nan) , so we replace them do a count to check with competition information \n",
    "# and also keep position i and j position in the matrix in two separate  \n",
    "def transform_empty_toNumpyNan(filename):\n",
    "    \"\"\"\n",
    "    input  : raw csv matrix\n",
    "    output : matrix with empty replaced by nans\n",
    "             nan_elements_number as the total_number of nan\n",
    "             ipos_rawdata and jpos_rawdata containing couple of the i and the j of each nan position\n",
    "             \n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        raw_data = list(reader)\n",
    "        total_zeros = 0\n",
    "        nan_elements_number = 0\n",
    "        ipos_rawdata = []\n",
    "        jpos_rawdata = []\n",
    "        non_nul_per_user_array = np.zeros(len(raw_data))\n",
    "        for j in range(len(raw_data[0])):\n",
    "                #row/user\n",
    "            for i in range(len(raw_data)):\n",
    "\n",
    "                if(raw_data[i][j])==\"\":\n",
    "\n",
    "                    nan_elements_number +=1\n",
    "                    ipos_rawdata.append(i)\n",
    "                    jpos_rawdata.append(j)\n",
    "                    raw_data[i][j] = np.nan\n",
    "                else:\n",
    "                    raw_data[i][j]=int(raw_data[i][j])\n",
    "                    if raw_data[i][j] > 0.0 :\n",
    "                        non_nul_per_user_array[i]+=1\n",
    "                \n",
    "    return raw_data,nan_elements_number,ipos_rawdata,jpos_rawdata,non_nul_per_user_array\n",
    "\n",
    "raw_data_transformed, nan_elements_number,ipos_rawdata,jpos_rawdata,non_nul_per_user_array = transform_empty_toNumpyNan('user_artist_matrix_with_nans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_number_of_elemnt = (user_number * item_number) *1.0\n",
    "print \"nan number : \", nan_elements_number\n",
    "print \"nan ratio : \", nan_elements_number/total_number_of_elemnt\n",
    "print \"sparcity ratio :\", (total_number_of_elemnt - np.count_nonzero(raw_data_transformed))/total_number_of_elemnt\n",
    "print \"average non null values per user :\", int( np.mean(non_nul_per_user_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list of nans of every user i\n",
    "# for plotting\n",
    "unique_nans =[]\n",
    "for i in np.unique(ipos_rawdata):\n",
    "    unique_nan_i = []\n",
    "    for t in range(len(ipos_rawdata)):\n",
    "        if ipos_rawdata[t] == i :\n",
    "            unique_nan_i.append(jpos_rawdata[t])\n",
    "    unique_nans.append(unique_nan_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print unique_nans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_user_total_play(matrix):\n",
    "    \"\"\"\n",
    "    input  : user-item matrix\n",
    "    output : a list of couple (total_songs_user0, total_songs_user1, ..)\n",
    "    \"\"\"\n",
    "    user_artist_total = []\n",
    "    for i in range(0,np.shape(matrix)[0]):\n",
    "        user_artist_total.append(np.nansum(np.array(matrix[i])))\n",
    "    return user_artist_total\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_count_user_item = count_user_total_play(raw_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (15,4)\n",
    "plt.plot(np.arange(0,len(non_nul_per_user_array)), non_nul_per_user_array,'rx')\n",
    "plt.axis([0, len(total_count_user_item), 0, np.max(total_count_user_item)/3])\n",
    "plt.title('number of non nul nor nan per user')\n",
    "plt.figure(figsize=(40,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the mean number of unique songs listened by one user is nearly 795, which is low compared and prove \n",
    "# the difficulty of the difficulty of the task\n",
    "np.mean(total_count_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the maximum number of unique songs listened by one user is 5927\n",
    "np.max(total_count_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,10)\n",
    "plt.plot(np.arange(0,len(total_count_user_item)), total_count_user_item ,'ro')\n",
    "plt.axis([0, len(total_count_user_item), 0, np.max(total_count_user_item)])\n",
    "plt.title(\"number of total songs by user \")\n",
    "plt.figure(figsize=(40,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This was the simplest way to impute the nan value using SKlearn\n",
    "# gave no real result\n",
    "\n",
    "#from sklearn.preprocessing import Imputer\n",
    "#imp = Imputer(strategy=\"mean\")\n",
    "#aa = imp.fit_transform(raw_data_transformed)\n",
    "#score_to_write1 = []\n",
    "#for i in range(len(ipos_rawdata)):\n",
    "#    posi = ipos_rawdata[i]\n",
    "#    posj = jpos_rawdata[j]\n",
    "#    if aa[posi][posj] >=1.0 :\n",
    "#        aa[posi][posj] == 1.0\n",
    "#        score_to_write1.append(1)\n",
    "#    else :\n",
    "#        score_to_write1.append(0)\n",
    "        \n",
    "# Nope fail 0.4 :x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We first tried just brutal pearson correlation but this gave bad results too and the Pearseon is that we did not take\n",
    "# care of the nan values.\n",
    "from collections import Counter\n",
    "print \"number of colomn containing at least one nan value :\" , len(np.unique(jpos_rawdata))\n",
    "DD = Counter(ipos_rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.bar(range(len(DD)), DD.values())\n",
    "plt.xticks(range(len(DD)), DD.keys())\n",
    "plt.title(\"Histogram of nan values per user\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert in crab dictionary format\n",
    "#{userID:{itemID:preference, itemID2:preference2},\n",
    "#       userID2:{itemID:preference3,itemID4:preference5}}\n",
    "def convert_crab_format(matrix_data):\n",
    "    len_items = len(matrix_data[0])\n",
    "    len_users = len(matrix_data)\n",
    "    usr_item_dic = {}\n",
    "    t=0\n",
    "    f=0\n",
    "    non_dic = {}\n",
    "    for u in range(len_users):\n",
    "        items_prefs = {}\n",
    "        for i in range(len_items):\n",
    "            u_i_value = matrix_data[u][i]\n",
    "            #get only value >0 or have to predict\n",
    "            if u_i_value > 0 or np.isnan(u_i_value):\n",
    "                if np.isnan(u_i_value):\n",
    "                    t = t+1\n",
    "                    #if nan replace by zero \n",
    "                    u_i_value = 0\n",
    "                else:\n",
    "                    f = f+1\n",
    "                \n",
    "                items_prefs[i] = u_i_value\n",
    "        \n",
    "        usr_item_dic[u]= items_prefs\n",
    "    print \"number of nan:\", t, \" \",f\n",
    "    return usr_item_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users_items_dic = convert_crab_format(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pearson corellation for k neightboor users\n",
    "#return user and pearson corellation - knn k>2\n",
    "len_items=len(raw_data[1])\n",
    "len_users=len(raw_data)\n",
    "def knn_pearson_r(users_items_dic):\n",
    "#    if k <= 2:\n",
    "#        print \"k must be > 2\"\n",
    "#        return\n",
    "    #get_pearson_corrs = np.zeros(len_user)\n",
    "    get_scores = np.zeros((len_users,len_users),)\n",
    "    #print len_items\n",
    "    #print len_users\n",
    "#for i in range(len_items):\n",
    "\n",
    "    for i in range(len_users):\n",
    "        #get_pearson_corr = np.zeros(k)\n",
    "        for j in range(i,len_users):\n",
    "            \n",
    "            #if j==i:\n",
    "            #    \"don t compute auto corellation\"\n",
    "            #else:\n",
    "            #if get_scores[i][j]==0 and get_scores[j][i]==0    \n",
    "#print np.corrcoef(users_items_dic[0], users_items_dic[1])\n",
    "            keys = list(users_items_dic[i].viewkeys() & users_items_dic[j].viewkeys())\n",
    "            temp = np.corrcoef(\n",
    "                    [users_items_dic[i].get(x, 0) for x in keys],\n",
    "                    [users_items_dic[j].get(x, 0) for x in keys])[0, 1]\n",
    "        \n",
    "            #get_pearson_corr = temp\n",
    "            #print get_score[j]\n",
    "            get_scores[i][j] = temp\n",
    "            get_scores[j][i] = temp\n",
    "    return get_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implicit feed Back Matrix Factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "import time\n",
    "\n",
    "def load_matrix(filename, num_users, num_items):\n",
    "    t0 = time.time()\n",
    "    counts = np.zeros((num_users, num_items))\n",
    "    total = 0.0\n",
    "    num_zeros = num_users * num_items\n",
    "    for i, line in enumerate(open(filename, 'r')):\n",
    "        user, item, count = line.strip().split('\\t')\n",
    "        user = int(user)\n",
    "        item = int(item)\n",
    "        count = float(count)\n",
    "        if user >= num_users:\n",
    "            continue\n",
    "        if item >= num_items:\n",
    "            continue\n",
    "        if count != 0:\n",
    "            counts[user, item] = count\n",
    "            total += count\n",
    "            num_zeros -= 1\n",
    "        if i % 100000 == 0:\n",
    "            print 'loaded %i counts...' % i\n",
    "    alpha = num_zeros / total\n",
    "    print 'alpha %.2f' % alpha\n",
    "    counts *= alpha\n",
    "    counts = sparse.csr_matrix(counts)\n",
    "    t1 = time.time()\n",
    "    print 'Finished loading matrix in %f seconds' % (t1 - t0)\n",
    "    return counts\n",
    "\n",
    "\n",
    "class ImplicitMF():\n",
    "\n",
    "    def __init__(self, counts, num_factors=40, num_iterations=30,\n",
    "                 reg_param=0.8):\n",
    "        self.counts = counts\n",
    "        self.num_users = counts.shape[0]\n",
    "        self.num_items = counts.shape[1]\n",
    "        self.num_factors = num_factors\n",
    "        self.num_iterations = num_iterations\n",
    "        self.reg_param = reg_param\n",
    "\n",
    "    def train_model(self):\n",
    "        self.user_vectors = np.random.normal(size=(self.num_users,\n",
    "                                                   self.num_factors))\n",
    "        self.item_vectors = np.random.normal(size=(self.num_items,\n",
    "                                                   self.num_factors))\n",
    "\n",
    "        for i in xrange(self.num_iterations):\n",
    "            t0 = time.time()\n",
    "            print 'Solving for user vectors...'\n",
    "            self.user_vectors = self.iteration(True, sparse.csr_matrix(self.item_vectors))\n",
    "            print 'Solving for item vectors...'\n",
    "            self.item_vectors = self.iteration(False, sparse.csr_matrix(self.user_vectors))\n",
    "            t1 = time.time()\n",
    "            print 'iteration %i finished in %f seconds' % (i + 1, t1 - t0)\n",
    "\n",
    "    def iteration(self, user, fixed_vecs):\n",
    "        num_solve = self.num_users if user else self.num_items\n",
    "        num_fixed = fixed_vecs.shape[0]\n",
    "        YTY = fixed_vecs.T.dot(fixed_vecs)\n",
    "        eye = sparse.eye(num_fixed)\n",
    "        lambda_eye = self.reg_param * sparse.eye(self.num_factors)\n",
    "        solve_vecs = np.zeros((num_solve, self.num_factors))\n",
    "\n",
    "        t = time.time()\n",
    "        for i in xrange(num_solve):\n",
    "            if user:\n",
    "                counts_i = self.counts[i].toarray()\n",
    "            else:\n",
    "                counts_i = self.counts[:, i].T.toarray()\n",
    "            CuI = sparse.diags(counts_i, [0])\n",
    "            pu = counts_i.copy()\n",
    "            pu[np.where(pu != 0)] = 1.0\n",
    "            YTCuIY = fixed_vecs.T.dot(CuI).dot(fixed_vecs)\n",
    "            YTCupu = fixed_vecs.T.dot(CuI + eye).dot(sparse.csr_matrix(pu).T)\n",
    "            xu = spsolve(YTY + YTCuIY + lambda_eye, YTCupu)\n",
    "            solve_vecs[i] = xu\n",
    "            if i % 1000 == 0:\n",
    "                print 'Solved %i vecs in %d seconds' % (i, time.time() - t)\n",
    "                t = time.time()\n",
    "\n",
    "        return solve_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "\n",
    "def load_matrix2(raw_data_transformed):\n",
    "    where_nan = np.isnan(raw_data_transformed)\n",
    "    raw_data_no_nans = np.copy(raw_data_transformed)\n",
    "    raw_data_no_nans[where_nan]= 0\n",
    "    total_number_of_elemnt = (np.shape(raw_data_no_nans)[0] * np.shape(raw_data_no_nans)[1]) *1.0\n",
    "    print total_number_of_elemnt\n",
    "    alpha = (total_number_of_elemnt - np.count_nonzero(raw_data_no_nans)) / np.sum(raw_data_no_nans) \n",
    "    print alpha\n",
    "    counts = np.copy(raw_data_no_nans)\n",
    "    print 'alpha %.2f' % alpha\n",
    "    counts *= alpha\n",
    "    counts = sparse.csr_matrix(counts)\n",
    "    return counts\n",
    "\n",
    "counts_MF = load_matrix2(raw_data_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reg param = 0.8\n",
    "# 40 factors and 30 iterations obtained 0.852 at best with threshold = 0.2\n",
    "# 40 factors and 80 iterations obtained \n",
    "# 10 factors and 50 iterations obtained 0.849 at best with threshold = 0.21\n",
    "# 30 factors and 50 iterations obtained 0.85935 at best with threshold = 0.22\n",
    "# 30 factors and 100 iterations obtained 0.85935 at best with threshold = 0.22\n",
    "#reg param 0.5 \n",
    "# 30 factors and 50 iterations obtained 0.85529 at best with threshold = 0.16\n",
    "#reg param 0.9\n",
    "# 50 factors and 60 iterations obtained 0.84\n",
    "\n",
    "implicit_factor_instance = ImplicitMF(counts_MF,num_factors=30, num_iterations=100,\n",
    "                 reg_param=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "implicit_factor_instance.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reconstruction of the matrix\n",
    "solved_mat = np.dot(implicit_factor_instance.user_vectors,implicit_factor_instance.item_vectors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rating list contains 5615 neg element, I will first try to put negative value to 0 and others to 1 \n",
    "def generate_rating_list(solved_mat,ipos,jpos,threshold):\n",
    "    res_rating_list = []\n",
    "    factored_rating_list=[]\n",
    "    for i in range(len(ipos)):\n",
    "        item_id = jpos[i]\n",
    "        user_id = ipos[i]\n",
    "        factored_rating_list.append(solved_mat[user_id][item_id])\n",
    "        if solved_mat[user_id][item_id]<= threshold :\n",
    "            res_rating_list.append(0)\n",
    "        else:\n",
    "            res_rating_list.append(1)\n",
    "    return factored_rating_list, res_rating_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_id_submission(ipos,jpos):\n",
    "    \"\"\"\n",
    "    We can still use the id from the submission file, but using the one we generate we are pretty\n",
    "    sure we are submitting the correct ones or the submission system will reject it \n",
    "    \"\"\"\n",
    "    id_prediction = []\n",
    "    #user\n",
    "    for i in range(len(ipos)):\n",
    "        #item\n",
    "        id_prediction.append((ipos[i] + 1) + jpos[i] * 1372)\n",
    "    return id_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_submission(filename,rating_list,id_prediction):\n",
    "    with open(filename, 'rb') as f:\n",
    "        reader = csv.reader(f)\n",
    "        raw_submission_data = list(reader)\n",
    "    with open(filename, 'wb') as h:\n",
    "        s = \"Id\"\n",
    "        b= \"Prediction\"\n",
    "        writer = csv.writer(h)\n",
    "        writer.writerow((s,b))\n",
    "        for i in range(len(id_prediction)):\n",
    "            writer.writerow((id_prediction[i],int(rating_list[i])))\n",
    "    print len(raw_submission_data) \n",
    "    print \"file generated succesfully, Good Luck Bro !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_prediction = generate_id_submission(ipos_rawdata,jpos_rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 1.62647929442\n",
      "min : -0.727725458125\n",
      "mean : 0.426616597282\n"
     ]
    }
   ],
   "source": [
    "factore_rating_list,scaled_rating_list = generate_rating_list(solved_mat,ipos_rawdata,jpos_rawdata,0.225)\n",
    "print \"max :\", np.max(factore_rating_list)\n",
    "print 'min :', np.min(factore_rating_list)\n",
    "print 'mean :',np.mean(factore_rating_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35022\n",
      "file generated succesfully, Good Luck Bro !\n"
     ]
    }
   ],
   "source": [
    "generate_submission('sampleSubmission.csv',scaled_rating_list,id_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
